{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-FJIheV06tov",
        "outputId": "a1a45096-3652-48ef-c81e-2401141f57de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "#Connecting colab to drive\n",
        "from google.colab import drive \n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wIz3pvwhES2e",
        "outputId": "f2e34237-a364-4254-987b-e7a0f9d69d82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'project_vg'...\n",
            "remote: Enumerating objects: 21, done.\u001b[K\n",
            "remote: Total 21 (delta 0), reused 0 (delta 0), pack-reused 21\u001b[K\n",
            "Unpacking objects: 100% (21/21), done.\n"
          ]
        }
      ],
      "source": [
        "#Cloning github material into our drive\n",
        "!git clone https://github.com/gmberton/project_vg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yQ8LM6H8HPIa"
      },
      "outputs": [],
      "source": [
        "#Unzipping pitts30k\n",
        "import zipfile \n",
        "with zipfile.ZipFile(\"/content/drive/MyDrive/IAperso/pitts30k.zip\",\"r\") as zip_ref:\n",
        "  zip_ref.extractall(\"/content/drive/MyDrive/IAperso\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ezhEdvhLzjZg"
      },
      "outputs": [],
      "source": [
        "#Unzipping st_lucia\n",
        "import zipfile \n",
        "with zipfile.ZipFile(\"/content/drive/MyDrive/IAperso/st_lucia.zip\",\"r\") as zip_ref:\n",
        "  zip_ref.extractall(\"/content/drive/MyDrive/IAperso\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x2NKdpgAGERs",
        "outputId": "04fed22b-bd03-44f3-ab08-3573107f76d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mv: cannot stat '/content/project_vg': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "#Moving project_vg to the folder we want\n",
        "!mv \"/content/project_vg\" \"/content/drive/MyDrive/IAperso\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ogev4k-4G08U",
        "outputId": "a3cf6df3-685a-4fe7-ab66-d00c7b94e79e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1TlK0tcZaPtpj1I0jXcKNsWz97iRnMR96/IA_project/project_vg\n"
          ]
        }
      ],
      "source": [
        "#Putting into the colab what's inside project_vg\n",
        "%cd \"/content/drive/MyDrive/IA_project/project_vg\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7Y94OAD1NC2I",
        "outputId": "d77810f8-9c6a-4f01-87ee-672518feb810"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faiss_cpu==1.7.1\n",
            "  Downloading faiss_cpu-1.7.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.4 MB 6.5 MB/s \n",
            "\u001b[?25hInstalling collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.7.1\n",
            "Collecting numpy==1.19.4\n",
            "  Downloading numpy-1.19.4-cp37-cp37m-manylinux2010_x86_64.whl (14.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 14.5 MB 6.8 MB/s \n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.19.5\n",
            "    Uninstalling numpy-1.19.5:\n",
            "      Successfully uninstalled numpy-1.19.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed numpy-1.19.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting Pillow==8.4.0\n",
            "  Downloading Pillow-8.4.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 6.7 MB/s \n",
            "\u001b[?25hInstalling collected packages: Pillow\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: Pillow 7.1.2\n",
            "    Uninstalling Pillow-7.1.2:\n",
            "      Successfully uninstalled Pillow-7.1.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed Pillow-8.4.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikit_learn==1.0.1\n",
            "  Downloading scikit_learn-1.0.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (23.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 23.2 MB 1.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit_learn==1.0.1) (1.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit_learn==1.0.1) (1.4.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit_learn==1.0.1) (3.0.0)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit_learn==1.0.1) (1.19.4)\n",
            "Installing collected packages: scikit-learn\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.0.2\n",
            "    Uninstalling scikit-learn-1.0.2:\n",
            "      Successfully uninstalled scikit-learn-1.0.2\n",
            "Successfully installed scikit-learn-1.0.1\n",
            "Collecting torch==1.7.0\n",
            "  Downloading torch-1.7.0-cp37-cp37m-manylinux1_x86_64.whl (776.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 776.7 MB 4.4 kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.7.0) (1.19.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.7.0) (3.10.0.2)\n",
            "Collecting dataclasses\n",
            "  Downloading dataclasses-0.6-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch==1.7.0) (0.16.0)\n",
            "Installing collected packages: dataclasses, torch\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.10.0+cu111\n",
            "    Uninstalling torch-1.10.0+cu111:\n",
            "      Successfully uninstalled torch-1.10.0+cu111\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.11.1+cu111 requires torch==1.10.0, but you have torch 1.7.0 which is incompatible.\n",
            "torchtext 0.11.0 requires torch==1.10.0, but you have torch 1.7.0 which is incompatible.\n",
            "torchaudio 0.10.0+cu111 requires torch==1.10.0, but you have torch 1.7.0 which is incompatible.\u001b[0m\n",
            "Successfully installed dataclasses-0.6 torch-1.7.0\n",
            "Collecting torchvision==0.8.1\n",
            "  Downloading torchvision-0.8.1-cp37-cp37m-manylinux1_x86_64.whl (12.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.7 MB 8.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.8.1) (8.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision==0.8.1) (1.19.4)\n",
            "Requirement already satisfied: torch==1.7.0 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.8.1) (1.7.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch==1.7.0->torchvision==0.8.1) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.7.0->torchvision==0.8.1) (3.10.0.2)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.7/dist-packages (from torch==1.7.0->torchvision==0.8.1) (0.6)\n",
            "Installing collected packages: torchvision\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.11.1+cu111\n",
            "    Uninstalling torchvision-0.11.1+cu111:\n",
            "      Successfully uninstalled torchvision-0.11.1+cu111\n",
            "Successfully installed torchvision-0.8.1\n",
            "Collecting tqdm==4.48.2\n",
            "  Downloading tqdm-4.48.2-py2.py3-none-any.whl (68 kB)\n",
            "\u001b[K     |████████████████████████████████| 68 kB 4.9 MB/s \n",
            "\u001b[?25hInstalling collected packages: tqdm\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.62.3\n",
            "    Uninstalling tqdm-4.62.3:\n",
            "      Successfully uninstalled tqdm-4.62.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.11.0 requires torch==1.10.0, but you have torch 1.7.0 which is incompatible.\u001b[0m\n",
            "Successfully installed tqdm-4.48.2\n"
          ]
        }
      ],
      "source": [
        "#Installing requirements for our code\n",
        "!pip install faiss_cpu==1.7.1\n",
        "!pip install numpy==1.19.4\n",
        "!pip install Pillow==8.4.0\n",
        "!pip install scikit_learn==1.0.1\n",
        "!pip install torch==1.7.0\n",
        "!pip install torchvision==0.8.1\n",
        "!pip install tqdm==4.48.2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Training the model on Pittks30k\n",
        "!python3 train.py --datasets_folder\"/content/drive/MyDrive/IAperso\""
      ],
      "metadata": {
        "id": "fL7L0Yt7XOzW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ncAMhutiQ6AF",
        "outputId": "a5c14085-2ada-484b-88fe-5c0c2a1b0aeb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:279: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\n",
            "  warnings.warn(\"The use of the transforms.Scale transform is deprecated, \" +\n",
            "2022-01-16 15:46:46   Arguments: Namespace(cache_refresh_rate=1000, datasets_folder='/content/drive/MyDrive/IAperso', device='cuda', epochs_num=5, exp_name='default', infer_batch_size=16, lr=1e-06, margin=0.1, neg_samples_num=1000, negs_num_per_query=10, num_workers=8, output_folder='runs/default/2022-01-16_15-46-45', patience=3, queries_per_epoch=5000, recall_values=[1, 5, 10, 20], seed=0, train_batch_size=4, train_positives_dist_threshold=10, val_positive_dist_threshold=25)\n",
            "2022-01-16 15:46:46   The outputs are being saved in runs/default/2022-01-16_15-46-45\n",
            "2022-01-16 15:46:46   Using 1 GPUs and 2 CPUs\n",
            "2022-01-16 15:46:46   Loading dataset Pitts30k from folder /content/drive/MyDrive/IAperso\n",
            "2022-01-16 15:47:46   There are 96 queries without any positives within the training set. They won't be considered as they're useless for training.\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n",
            "2022-01-16 15:47:46   Train query set: < TripletsDataset, pitts30k - #database: 10000; #queries: 7320 >\n",
            "2022-01-16 15:49:05   Val set: < BaseDataset, pitts30k - #database: 10000; #queries: 6794 >\n",
            "2022-01-16 15:50:20   Test set: < BaseDataset, pitts30k - #database: 10000; #queries: 6816 >\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-5c106cde.pth\n",
            "100% 44.7M/44.7M [00:03<00:00, 13.3MB/s]\n",
            "2022-01-16 15:50:25   Train only conv4 of the ResNet-18 (remove conv5), freeze the previous ones\n",
            "2022-01-16 15:50:28   Output dimension of the model is 256\n",
            "2022-01-16 15:50:28   Start training epoch: 00\n",
            "2022-01-16 15:50:28   Cache: 0 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [07:22<00:00,  1.56it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 870.39it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [01:34<00:00,  2.65it/s]\n",
            "2022-01-16 15:59:26   Epoch[00](0/5): current batch triplet loss = 0.0475, average epoch triplet loss = 0.0575\n",
            "2022-01-16 15:59:26   Cache: 1 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [01:56<00:00,  5.90it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 866.05it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [01:36<00:00,  2.59it/s]\n",
            "2022-01-16 16:03:00   Epoch[00](1/5): current batch triplet loss = 0.0803, average epoch triplet loss = 0.0576\n",
            "2022-01-16 16:03:00   Cache: 2 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [01:47<00:00,  6.41it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 877.45it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [01:35<00:00,  2.61it/s]\n",
            "2022-01-16 16:06:24   Epoch[00](2/5): current batch triplet loss = 0.0597, average epoch triplet loss = 0.0572\n",
            "2022-01-16 16:06:24   Cache: 3 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [01:42<00:00,  6.72it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 898.01it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [01:35<00:00,  2.61it/s]\n",
            "2022-01-16 16:09:43   Epoch[00](3/5): current batch triplet loss = 0.0893, average epoch triplet loss = 0.0572\n",
            "2022-01-16 16:09:43   Cache: 4 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [01:39<00:00,  6.91it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 891.35it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [01:35<00:00,  2.61it/s]\n",
            "2022-01-16 16:13:00   Epoch[00](4/5): current batch triplet loss = 0.0734, average epoch triplet loss = 0.0575\n",
            "2022-01-16 16:13:00   Finished epoch 00 in 0:22:32, average epoch triplet loss = 0.0575\n",
            "2022-01-16 16:13:00   Extracting database features for evaluation/testing\n",
            "100%|█████████████████████████████████████████████████████████████| 625/625 [04:55<00:00,  2.12it/s]\n",
            "2022-01-16 16:17:55   Extracting queries features for evaluation/testing\n",
            "100%|█████████████████████████████████████████████████████████████| 425/425 [03:13<00:00,  2.20it/s]\n",
            "2022-01-16 16:21:08   Calculating recalls\n",
            "2022-01-16 16:21:09   Recalls on val set < BaseDataset, pitts30k - #database: 10000; #queries: 6794 >: R@1: 62.0, R@5: 81.5, R@10: 87.1, R@20: 91.8\n",
            "2022-01-16 16:21:09   Improved: previous best R@5 = 0.0, current R@5 = 81.5\n",
            "2022-01-16 16:21:09   Start training epoch: 01\n",
            "2022-01-16 16:21:09   Cache: 0 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [01:38<00:00,  7.02it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 870.42it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [01:34<00:00,  2.63it/s]\n",
            "2022-01-16 16:24:24   Epoch[01](0/5): current batch triplet loss = 0.0762, average epoch triplet loss = 0.0574\n",
            "2022-01-16 16:24:24   Cache: 1 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [01:34<00:00,  7.30it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 877.30it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [01:35<00:00,  2.62it/s]\n",
            "2022-01-16 16:27:34   Epoch[01](1/5): current batch triplet loss = 0.0434, average epoch triplet loss = 0.0576\n",
            "2022-01-16 16:27:34   Cache: 2 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [01:31<00:00,  7.48it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 875.49it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [01:36<00:00,  2.59it/s]\n",
            "2022-01-16 16:30:44   Epoch[01](2/5): current batch triplet loss = 0.0706, average epoch triplet loss = 0.0579\n",
            "2022-01-16 16:30:44   Cache: 3 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [01:31<00:00,  7.51it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 884.50it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [01:33<00:00,  2.67it/s]\n",
            "2022-01-16 16:33:50   Epoch[01](3/5): current batch triplet loss = 0.0747, average epoch triplet loss = 0.0582\n",
            "2022-01-16 16:33:50   Cache: 4 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [01:27<00:00,  7.87it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 889.04it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [01:33<00:00,  2.67it/s]\n",
            "2022-01-16 16:36:52   Epoch[01](4/5): current batch triplet loss = 0.0712, average epoch triplet loss = 0.0585\n",
            "2022-01-16 16:36:52   Finished epoch 01 in 0:15:42, average epoch triplet loss = 0.0585\n",
            "2022-01-16 16:36:52   Extracting database features for evaluation/testing\n",
            "100%|█████████████████████████████████████████████████████████████| 625/625 [01:16<00:00,  8.21it/s]\n",
            "2022-01-16 16:38:08   Extracting queries features for evaluation/testing\n",
            "100%|█████████████████████████████████████████████████████████████| 425/425 [00:51<00:00,  8.33it/s]\n",
            "2022-01-16 16:39:00   Calculating recalls\n",
            "2022-01-16 16:39:01   Recalls on val set < BaseDataset, pitts30k - #database: 10000; #queries: 6794 >: R@1: 64.2, R@5: 83.0, R@10: 88.4, R@20: 92.7\n",
            "2022-01-16 16:39:01   Improved: previous best R@5 = 81.5, current R@5 = 83.0\n",
            "2022-01-16 16:39:01   Start training epoch: 02\n",
            "2022-01-16 16:39:01   Cache: 0 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [01:27<00:00,  7.85it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 875.10it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [01:34<00:00,  2.65it/s]\n",
            "2022-01-16 16:42:04   Epoch[02](0/5): current batch triplet loss = 0.0663, average epoch triplet loss = 0.0577\n",
            "2022-01-16 16:42:04   Cache: 1 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [01:25<00:00,  8.08it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 862.48it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [01:33<00:00,  2.66it/s]\n",
            "2022-01-16 16:45:04   Epoch[02](1/5): current batch triplet loss = 0.0536, average epoch triplet loss = 0.0584\n",
            "2022-01-16 16:45:04   Cache: 2 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [01:25<00:00,  8.08it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 866.78it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [01:34<00:00,  2.66it/s]\n",
            "2022-01-16 16:48:05   Epoch[02](2/5): current batch triplet loss = 0.0307, average epoch triplet loss = 0.0585\n",
            "2022-01-16 16:48:05   Cache: 3 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [01:24<00:00,  8.12it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 867.73it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [01:35<00:00,  2.63it/s]\n",
            "2022-01-16 16:51:06   Epoch[02](3/5): current batch triplet loss = 0.0443, average epoch triplet loss = 0.0581\n",
            "2022-01-16 16:51:06   Cache: 4 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [01:24<00:00,  8.19it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 876.89it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [01:35<00:00,  2.63it/s]\n",
            "2022-01-16 16:54:06   Epoch[02](4/5): current batch triplet loss = 0.0782, average epoch triplet loss = 0.0581\n",
            "2022-01-16 16:54:06   Finished epoch 02 in 0:15:04, average epoch triplet loss = 0.0581\n",
            "2022-01-16 16:54:06   Extracting database features for evaluation/testing\n",
            "100%|█████████████████████████████████████████████████████████████| 625/625 [01:16<00:00,  8.15it/s]\n",
            "2022-01-16 16:55:23   Extracting queries features for evaluation/testing\n",
            "100%|█████████████████████████████████████████████████████████████| 425/425 [00:51<00:00,  8.27it/s]\n",
            "2022-01-16 16:56:14   Calculating recalls\n",
            "2022-01-16 16:56:15   Recalls on val set < BaseDataset, pitts30k - #database: 10000; #queries: 6794 >: R@1: 66.1, R@5: 84.4, R@10: 89.5, R@20: 93.6\n",
            "2022-01-16 16:56:15   Improved: previous best R@5 = 83.0, current R@5 = 84.4\n",
            "2022-01-16 16:56:15   Start training epoch: 03\n",
            "2022-01-16 16:56:15   Cache: 0 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [01:24<00:00,  8.17it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 861.96it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [01:34<00:00,  2.63it/s]\n",
            "2022-01-16 16:59:16   Epoch[03](0/5): current batch triplet loss = 0.0410, average epoch triplet loss = 0.0560\n",
            "2022-01-16 16:59:16   Cache: 1 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [01:23<00:00,  8.24it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 872.18it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [01:35<00:00,  2.62it/s]\n",
            "2022-01-16 17:02:16   Epoch[03](1/5): current batch triplet loss = 0.0535, average epoch triplet loss = 0.0569\n",
            "2022-01-16 17:02:16   Cache: 2 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [01:23<00:00,  8.27it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 869.42it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [01:34<00:00,  2.66it/s]\n",
            "2022-01-16 17:05:14   Epoch[03](2/5): current batch triplet loss = 0.0512, average epoch triplet loss = 0.0576\n",
            "2022-01-16 17:05:14   Cache: 3 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [01:22<00:00,  8.29it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 875.00it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [01:34<00:00,  2.65it/s]\n",
            "2022-01-16 17:08:12   Epoch[03](3/5): current batch triplet loss = 0.0703, average epoch triplet loss = 0.0576\n",
            "2022-01-16 17:08:12   Cache: 4 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [01:22<00:00,  8.29it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 872.62it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [01:34<00:00,  2.64it/s]\n",
            "2022-01-16 17:11:11   Epoch[03](4/5): current batch triplet loss = 0.0813, average epoch triplet loss = 0.0578\n",
            "2022-01-16 17:11:11   Finished epoch 03 in 0:14:55, average epoch triplet loss = 0.0578\n",
            "2022-01-16 17:11:11   Extracting database features for evaluation/testing\n",
            "100%|█████████████████████████████████████████████████████████████| 625/625 [01:16<00:00,  8.22it/s]\n",
            "2022-01-16 17:12:27   Extracting queries features for evaluation/testing\n",
            "100%|█████████████████████████████████████████████████████████████| 425/425 [00:51<00:00,  8.30it/s]\n",
            "2022-01-16 17:13:19   Calculating recalls\n",
            "2022-01-16 17:13:20   Recalls on val set < BaseDataset, pitts30k - #database: 10000; #queries: 6794 >: R@1: 67.7, R@5: 85.5, R@10: 90.6, R@20: 94.4\n",
            "2022-01-16 17:13:20   Improved: previous best R@5 = 84.4, current R@5 = 85.5\n",
            "2022-01-16 17:13:20   Start training epoch: 04\n",
            "2022-01-16 17:13:20   Cache: 0 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [01:22<00:00,  8.38it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 875.31it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [01:33<00:00,  2.66it/s]\n",
            "2022-01-16 17:16:17   Epoch[04](0/5): current batch triplet loss = 0.0323, average epoch triplet loss = 0.0571\n",
            "2022-01-16 17:16:17   Cache: 1 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [01:22<00:00,  8.36it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 880.62it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [01:33<00:00,  2.68it/s]\n",
            "2022-01-16 17:19:14   Epoch[04](1/5): current batch triplet loss = 0.0637, average epoch triplet loss = 0.0567\n",
            "2022-01-16 17:19:14   Cache: 2 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [01:21<00:00,  8.44it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 874.08it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [01:32<00:00,  2.69it/s]\n",
            "2022-01-16 17:22:09   Epoch[04](2/5): current batch triplet loss = 0.0604, average epoch triplet loss = 0.0571\n",
            "2022-01-16 17:22:09   Cache: 3 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [01:21<00:00,  8.46it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 884.37it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [01:33<00:00,  2.68it/s]\n",
            "2022-01-16 17:25:05   Epoch[04](3/5): current batch triplet loss = 0.0512, average epoch triplet loss = 0.0570\n",
            "2022-01-16 17:25:05   Cache: 4 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [01:22<00:00,  8.37it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 877.31it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [01:33<00:00,  2.69it/s]\n",
            "2022-01-16 17:28:01   Epoch[04](4/5): current batch triplet loss = 0.0498, average epoch triplet loss = 0.0571\n",
            "2022-01-16 17:28:01   Finished epoch 04 in 0:14:41, average epoch triplet loss = 0.0571\n",
            "2022-01-16 17:28:01   Extracting database features for evaluation/testing\n",
            "100%|█████████████████████████████████████████████████████████████| 625/625 [01:14<00:00,  8.40it/s]\n",
            "2022-01-16 17:29:16   Extracting queries features for evaluation/testing\n",
            "100%|█████████████████████████████████████████████████████████████| 425/425 [00:50<00:00,  8.40it/s]\n",
            "2022-01-16 17:30:06   Calculating recalls\n",
            "2022-01-16 17:30:08   Recalls on val set < BaseDataset, pitts30k - #database: 10000; #queries: 6794 >: R@1: 68.9, R@5: 86.2, R@10: 90.9, R@20: 94.8\n",
            "2022-01-16 17:30:08   Improved: previous best R@5 = 85.5, current R@5 = 86.2\n",
            "2022-01-16 17:30:08   Best R@5: 86.2\n",
            "2022-01-16 17:30:08   Trained for 05 epochs, in total in 1:43:22\n",
            "2022-01-16 17:30:08   Extracting database features for evaluation/testing\n",
            " 27%|████████████████▍                                            | 169/625 [02:13<08:16,  1.09s/it]2022-01-16 17:32:22   \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tqdm/std.py\", line 1130, in __iter__\n",
            "    for obj in iterable:\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 435, in __next__\n",
            "    data = self._next_data()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1068, in _next_data\n",
            "    idx, data = self._get_data()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1024, in _get_data\n",
            "    success, data = self._try_get_data()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 872, in _try_get_data\n",
            "    data = self._data_queue.get(timeout=timeout)\n",
            "  File \"/usr/lib/python3.7/queue.py\", line 179, in get\n",
            "    self.not_empty.wait(remaining)\n",
            "  File \"/usr/lib/python3.7/threading.py\", line 300, in wait\n",
            "    gotit = waiter.acquire(True, timeout)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"train.py\", line 145, in <module>\n",
            "    recalls, recalls_str = test.test(args, test_ds, model)\n",
            "  File \"/content/drive/.shortcut-targets-by-id/1TlK0tcZaPtpj1I0jXcKNsWz97iRnMR96/IA_project/project_vg/test.py\", line 22, in test\n",
            "    for inputs, indices in tqdm(database_dataloader, ncols=100):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tqdm/std.py\", line 1183, in __iter__\n",
            "    self.close()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tqdm/std.py\", line 1271, in close\n",
            "    self._decr_instances(self)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tqdm/std.py\", line 572, in _decr_instances\n",
            "    cls.monitor.exit()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tqdm/_monitor.py\", line 53, in exit\n",
            "    self.join()\n",
            "  File \"/usr/lib/python3.7/threading.py\", line 1044, in join\n",
            "    self._wait_for_tstate_lock()\n",
            "  File \"/usr/lib/python3.7/threading.py\", line 1060, in _wait_for_tstate_lock\n",
            "    elif lock.acquire(block, timeout):\n",
            "KeyboardInterrupt\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Modifying learning rate\n",
        "!python3 train.py --datasets_folder \"/content/drive/MyDrive/IAperso\" --lr 0.000001"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Testing the code on Pitts30k\n",
        "!python3 Pitts30k_test_code.py --datasets_folder \"/content/drive/MyDrive/IAperso\""
      ],
      "metadata": {
        "id": "_MVQMaUxY-8b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Testing the code on st_lucia\n",
        "!python3 St_lucia_test_code.py --datasets_folder \"/content/drive/MyDrive/IAperso\""
      ],
      "metadata": {
        "id": "iYqIi9UzXc0J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "noc73icxaE7E",
        "outputId": "ad380c28-d10f-4a40-e056-f56bee84f60f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-01-15 11:05:29   Arguments: Namespace(cache_refresh_rate=1000, datasets_folder='/content/drive/MyDrive/IAperso', device='cuda', epochs_num=5, exp_name='default', infer_batch_size=16, lr=1e-05, margin=0.1, neg_samples_num=1000, negs_num_per_query=10, num_workers=8, output_folder='runs/default/2022-01-15_11-05-29', patience=3, queries_per_epoch=5000, recall_values=[1, 5, 10, 20], seed=0, train_batch_size=4, train_positives_dist_threshold=5, val_positive_dist_threshold=25)\n",
            "2022-01-15 11:05:29   The outputs are being saved in runs/default/2022-01-15_11-05-29\n",
            "2022-01-15 11:05:29   Using 1 GPUs and 2 CPUs\n",
            "2022-01-15 11:05:29   Loading dataset Pitts30k from folder /content/drive/MyDrive/IAperso\n",
            "2022-01-15 11:05:30   There are 2544 queries without any positives within the training set. They won't be considered as they're useless for training.\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n",
            "2022-01-15 11:05:30   Train query set: < TripletsDataset, pitts30k - #database: 10000; #queries: 4872 >\n",
            "2022-01-15 11:05:42   Val set: < BaseDataset, pitts30k - #database: 10000; #queries: 6794 >\n",
            "2022-01-15 11:05:42   Test set: < BaseDataset, st_lucia - #database: 1549; #queries: 1464 >\n",
            "2022-01-15 11:05:43   Train only conv4 of the ResNet-18 (remove conv5), freeze the previous ones\n",
            "2022-01-15 11:05:45   Output dimension of the model is 256\n",
            "2022-01-15 11:05:45   Start training epoch: 00\n",
            "2022-01-15 11:05:45   Cache: 0 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [03:25<00:00,  3.36it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 816.83it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [04:53<00:00,  1.18s/it]\n",
            "2022-01-15 11:14:05   Epoch[00](0/5): current batch triplet loss = 0.0806, average epoch triplet loss = 0.0660\n",
            "2022-01-15 11:14:05   Cache: 1 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [03:13<00:00,  3.55it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 809.88it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [04:52<00:00,  1.17s/it]\n",
            "2022-01-15 11:22:13   Epoch[00](1/5): current batch triplet loss = 0.0504, average epoch triplet loss = 0.0637\n",
            "2022-01-15 11:22:13   Cache: 2 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [03:10<00:00,  3.62it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 828.65it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [04:50<00:00,  1.16s/it]\n",
            "2022-01-15 11:30:15   Epoch[00](2/5): current batch triplet loss = 0.0467, average epoch triplet loss = 0.0606\n",
            "2022-01-15 11:30:15   Cache: 3 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [03:08<00:00,  3.65it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 816.12it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [04:52<00:00,  1.17s/it]\n",
            "2022-01-15 11:38:17   Epoch[00](3/5): current batch triplet loss = 0.0521, average epoch triplet loss = 0.0583\n",
            "2022-01-15 11:38:17   Cache: 4 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [03:07<00:00,  3.68it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 829.88it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [04:49<00:00,  1.16s/it]\n",
            "2022-01-15 11:46:15   Epoch[00](4/5): current batch triplet loss = 0.0377, average epoch triplet loss = 0.0566\n",
            "2022-01-15 11:46:15   Finished epoch 00 in 0:40:30, average epoch triplet loss = 0.0566\n",
            "2022-01-15 11:46:15   Extracting database features for evaluation/testing\n",
            "100%|█████████████████████████████████████████████████████████████| 625/625 [04:14<00:00,  2.46it/s]\n",
            "2022-01-15 11:50:29   Extracting queries features for evaluation/testing\n",
            "100%|█████████████████████████████████████████████████████████████| 425/425 [03:09<00:00,  2.25it/s]\n",
            "2022-01-15 11:53:38   Calculating recalls\n",
            "2022-01-15 11:53:40   Recalls on val set < BaseDataset, pitts30k - #database: 10000; #queries: 6794 >: R@1: 72.1, R@5: 87.4, R@10: 91.8, R@20: 95.0\n",
            "2022-01-15 11:53:40   Improved: previous best R@5 = 0.0, current R@5 = 87.4\n",
            "2022-01-15 11:53:40   Start training epoch: 01\n",
            "2022-01-15 11:53:40   Cache: 0 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [03:03<00:00,  3.74it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 785.44it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [04:54<00:00,  1.18s/it]\n",
            "2022-01-15 12:01:40   Epoch[01](0/5): current batch triplet loss = 0.0829, average epoch triplet loss = 0.0454\n",
            "2022-01-15 12:01:40   Cache: 1 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [03:04<00:00,  3.73it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 823.96it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [04:53<00:00,  1.17s/it]\n",
            "2022-01-15 12:09:39   Epoch[01](1/5): current batch triplet loss = 0.0426, average epoch triplet loss = 0.0438\n",
            "2022-01-15 12:09:39   Cache: 2 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [03:02<00:00,  3.76it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 829.76it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [04:53<00:00,  1.17s/it]\n",
            "2022-01-15 12:17:36   Epoch[01](2/5): current batch triplet loss = 0.0466, average epoch triplet loss = 0.0431\n",
            "2022-01-15 12:17:36   Cache: 3 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [03:04<00:00,  3.73it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 807.18it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [04:54<00:00,  1.18s/it]\n",
            "2022-01-15 12:25:37   Epoch[01](3/5): current batch triplet loss = 0.0247, average epoch triplet loss = 0.0421\n",
            "2022-01-15 12:25:37   Cache: 4 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [03:04<00:00,  3.73it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 803.40it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [04:52<00:00,  1.17s/it]\n",
            "2022-01-15 12:33:35   Epoch[01](4/5): current batch triplet loss = 0.0147, average epoch triplet loss = 0.0417\n",
            "2022-01-15 12:33:35   Finished epoch 01 in 0:39:55, average epoch triplet loss = 0.0417\n",
            "2022-01-15 12:33:35   Extracting database features for evaluation/testing\n",
            "100%|█████████████████████████████████████████████████████████████| 625/625 [02:47<00:00,  3.72it/s]\n",
            "2022-01-15 12:36:23   Extracting queries features for evaluation/testing\n",
            "100%|█████████████████████████████████████████████████████████████| 425/425 [01:54<00:00,  3.71it/s]\n",
            "2022-01-15 12:38:18   Calculating recalls\n",
            "2022-01-15 12:38:19   Recalls on val set < BaseDataset, pitts30k - #database: 10000; #queries: 6794 >: R@1: 76.4, R@5: 89.9, R@10: 93.5, R@20: 96.1\n",
            "2022-01-15 12:38:20   Improved: previous best R@5 = 87.4, current R@5 = 89.9\n",
            "2022-01-15 12:38:20   Start training epoch: 02\n",
            "2022-01-15 12:38:20   Cache: 0 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [03:02<00:00,  3.77it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 777.55it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [04:51<00:00,  1.17s/it]\n",
            "2022-01-15 12:46:15   Epoch[02](0/5): current batch triplet loss = 0.0414, average epoch triplet loss = 0.0378\n",
            "2022-01-15 12:46:15   Cache: 1 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [03:02<00:00,  3.76it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 811.22it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [04:51<00:00,  1.16s/it]\n",
            "2022-01-15 12:54:10   Epoch[02](1/5): current batch triplet loss = 0.0344, average epoch triplet loss = 0.0371\n",
            "2022-01-15 12:54:10   Cache: 2 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [03:02<00:00,  3.76it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 822.65it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [04:51<00:00,  1.16s/it]\n",
            "2022-01-15 13:02:05   Epoch[02](2/5): current batch triplet loss = 0.0105, average epoch triplet loss = 0.0375\n",
            "2022-01-15 13:02:05   Cache: 3 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [03:03<00:00,  3.75it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 814.83it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [04:53<00:00,  1.17s/it]\n",
            "2022-01-15 13:10:03   Epoch[02](3/5): current batch triplet loss = 0.0107, average epoch triplet loss = 0.0366\n",
            "2022-01-15 13:10:03   Cache: 4 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [03:03<00:00,  3.76it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 794.12it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [04:51<00:00,  1.17s/it]\n",
            "2022-01-15 13:17:59   Epoch[02](4/5): current batch triplet loss = 0.0453, average epoch triplet loss = 0.0364\n",
            "2022-01-15 13:17:59   Finished epoch 02 in 0:39:39, average epoch triplet loss = 0.0364\n",
            "2022-01-15 13:17:59   Extracting database features for evaluation/testing\n",
            " 79%|████████████████████████████████████████████████▏            | 494/625 [02:12<00:34,  3.76it/s]"
          ]
        }
      ],
      "source": [
        "#Training on Pitts30k with a different “train_positives_dist_threshold”\n",
        "!python3 train.py --datasets_folder \"/content/drive/MyDrive/IAperso\" --train_positives_dist_threshold 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4fogrMBr7wOR",
        "outputId": "f56e0977-9a68-4c2e-8bd4-837654344610"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-01-15 19:39:31   Arguments: Namespace(cache_refresh_rate=1000, datasets_folder='/content/drive/MyDrive/IAperso', device='cuda', epochs_num=5, exp_name='default', infer_batch_size=16, lr=1e-05, margin=0.1, neg_samples_num=1000, negs_num_per_query=10, num_workers=8, output_folder='runs/default/2022-01-15_19-39-31', patience=3, queries_per_epoch=5000, recall_values=[1, 5, 10, 20], seed=0, train_batch_size=4, train_positives_dist_threshold=10, val_positive_dist_threshold=15)\n",
            "2022-01-15 19:39:31   The outputs are being saved in runs/default/2022-01-15_19-39-31\n",
            "2022-01-15 19:39:31   Using 1 GPUs and 2 CPUs\n",
            "2022-01-15 19:39:31   Loading dataset StLucia from folder /content/drive/MyDrive/IAperso\n",
            "2022-01-15 19:39:31   Test set: < BaseDataset, st_lucia - #database: 1549; #queries: 1464 >\n",
            "2022-01-15 19:39:32   Train only conv4 of the ResNet-18 (remove conv5), freeze the previous ones\n",
            "2022-01-15 19:39:35   Output dimension of the model is 256\n",
            "2022-01-15 19:39:35   Extracting database features for evaluation/testing\n",
            "100%|███████████████████████████████████████████████████████████████| 97/97 [00:18<00:00,  5.22it/s]\n",
            "2022-01-15 19:39:53   Extracting queries features for evaluation/testing\n",
            "100%|███████████████████████████████████████████████████████████████| 92/92 [00:17<00:00,  5.28it/s]\n",
            "2022-01-15 19:40:11   Calculating recalls\n",
            "2022-01-15 19:40:11   Recalls on < BaseDataset, st_lucia - #database: 1549; #queries: 1464 >: R@1: 40.3, R@5: 56.6, R@10: 63.9, R@20: 69.8\n"
          ]
        }
      ],
      "source": [
        "#Testing on st_lucia with a different “val_positives_dist_threshold”\n",
        "!python3 St_lucia_test_code.py --datasets_folder \"/content/drive/MyDrive/IAperso\" --val_positive_dist_threshold 15"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Projet_IA",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}